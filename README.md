# GenAI-Class-notes-AI-Literacy-
Simplified course content 
# üìò AI Literacy Study Guide

This repository is a **study guide** covering core concepts from **Lessons 01‚Äì04** on Artificial Intelligence, Machine Learning, Deep Learning, Transformers, Generative AI, and GPTs.  
It is designed as a **layered reference**:
1. **Quick Reference (Most Important Terms)**
2. **Lesson-by-Lesson Drill Down**
3. **Cross-Lesson Connections**

---

## üîë Most Important Terms (Quick Reference)

- **Artificial Intelligence (AI)** ‚Äì Machines that mimic human intelligence.  
- **Machine Learning (ML)** ‚Äì AI that learns patterns from data.  
- **Deep Learning (DL)** ‚Äì Subset of ML using neural networks with many layers.  
- **Generative AI (GenAI)** ‚Äì AI that creates new content like text, images, and audio.  
- **Transformers** ‚Äì Model architecture powering modern NLP/LLMs, including GPT.  
- **Large Language Models (LLMs)** ‚Äì Transformer-based models trained on massive text corpora.  
- **Prompt Engineering** ‚Äì Crafting inputs to guide AI outputs.  
- **Few-Shot / Zero-Shot Learning** ‚Äì Using little or no training examples for tasks.  
- **Fine-Tuning** ‚Äì Customizing pre-trained models for specific domains/tasks.  
- **Chain-of-Thought Prompting** ‚Äì Encouraging step-by-step reasoning in GPTs.  
- **RLHF (Reinforcement Learning with Human Feedback)** ‚Äì Aligning AI outputs with human preferences.  
- **Responsible AI & Ethics** ‚Äì Ensuring fairness, safety, and explainability.  

---

## üìñ Lesson-by-Lesson Guide

### Lesson 01 ‚Äì Overview of AI, ML, and DL
AI is the broad field; ML and DL are subfields that provide the technical backbone.  
- **Artificial Intelligence (AI)**: Machines performing tasks requiring ‚Äúintelligence.‚Äù  
- **Machine Learning (ML)**: Algorithms that adapt by learning from data.  
- **Deep Learning (DL)**: ML using artificial neural networks.  
- **Learning Types**: Supervised, Unsupervised, Reinforcement Learning.  
- **Neural Networks**: Modeled on the human brain; foundation for DL.  

---

### Lesson 02 ‚Äì Transformers, Advanced AI Models, and NLP
Introduces the **transformer** architecture that enables modern language models.  
- **Transformer**: Core architecture for GPT, BERT, etc.  
- **Attention Mechanism (Self-Attention)**: Key innovation enabling models to focus on relevant context.  
- **BERT / GPT**: Examples of transformer-based LLMs.  
- **Embeddings**: Numeric representations of words/phrases.  
- **NLP (Natural Language Processing)**: Field of AI handling human language.  
- **Few-Shot / Zero-Shot Learning**: Introduced here, expanded later.  

---

### Lesson 03 ‚Äì Generative AI and AI Project Implementation
Focuses on **content creation AI** and ethical considerations.  
- **Generative AI (GenAI)**: Systems creating new content.  
- **GANs (Generative Adversarial Networks)**: Two-model setup for generating realistic data.  
- **Diffusion Models**: Used for modern image generation (e.g., Stable Diffusion, DALL¬∑E).  
- **Prompt Engineering**: Reinforced from Lesson 02; deepened in Lesson 04.  
- **Human-in-the-Loop (HITL)**: Humans supervise AI to ensure reliability.  
- **Responsible AI & AI Bias**: Core ethics framework.  
- **Explainable AI (XAI)**: Making outputs interpretable.  

---

### Lesson 04 ‚Äì Working with GPTs
Zooms into **practical usage of GPT models**.  
- **GPT (Generative Pre-Trained Transformer)**: Transformer-based LLM specialized for text generation.  
- **Fine-Tuning**: Customizing a GPT for a specific use case.  
- **Prompt Engineering**: Deep dive with structured approaches.  
- **Chain-of-Thought Prompting**: Encourages models to show reasoning steps.  
- **Few-Shot / Zero-Shot Learning**: Practical applications revisited.  
- **RLHF (Reinforcement Learning with Human Feedback)**: Combines reinforcement learning with human oversight
